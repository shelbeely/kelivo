# Generative UI Feature Documentation

## Overview

The Generative UI feature allows the Kelivo app to render interactive UI screens based on a JSON schema generated by an LLM. This works like [Cline](https://github.com/cline/cline) - a conversational UI pattern where:

1. **LLM generates UI** based on context and user requests
2. **User interacts** with the generated UI (buttons, forms, toggles, etc.)
3. **Interactions are sent back** to the LLM as events
4. **LLM responds** with updated UI based on user actions
5. **Loop continues** creating an interactive conversation

**Key Principles:**
- The LLM only emits structured JSON matching a strict schema
- No runtime code execution (`eval`) from LLM output
- All LLM output goes through schema validation before rendering
- User interactions are captured and sent back to the LLM for context

## Integration with Chat Interface

**NEW**: The generative UI is now integrated directly into the regular chat interface! When an LLM response contains valid generative UI JSON (with `screenId` and `blocks`), it will be rendered inline within the message.

### How it Works

1. The `ChatMessageWidget` detects generative UI JSON in assistant messages
2. The `InlineGenerativeUI` widget renders the UI blocks inline
3. User interactions trigger the `onGenerativeUIAction` callback
4. The callback can send interactions back to the LLM for dynamic updates

### Usage in Chat

```dart
ChatMessageWidget(
  message: chatMessage,
  // ... other props
  onGenerativeUIAction: (action) {
    // Handle the user interaction
    // This could send a follow-up message to the LLM
    print('User action: $action');
  },
)
```

### LLM Response Format

When using generative UI in chat, the LLM can include JSON in its response:

```
Here's an interactive dashboard for you:

{
  "screenId": "dashboard",
  "blocks": [
    {"type": "hero", "headline": "Welcome!", "icon": "sparkles"},
    {"type": "card", "headline": "Quick Actions", "body": [
      {"type": "text", "text": "Choose an option:"}
    ], "actions": [
      {"type": "button", "label": "Start Chat", "role": "primary_action", "action": {"type": "start_chat"}}
    ]}
  ]
}

You can click the button above to start a new conversation!
```

The widget will:
1. Render the text before the JSON
2. Render the interactive UI blocks
3. Render the text after the JSON

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    Conversation Loop                         │
│                                                              │
│   ┌──────────┐    Request/Event    ┌─────────────────────┐  │
│   │   User   │ ─────────────────>  │  GenerativeUISession │  │
│   └──────────┘                     │  (LLM Client)        │  │
│        ▲                           └──────────┬───────────┘  │
│        │                                      │              │
│        │ Rendered UI                         │ JSON Screen   │
│        │                                      ▼              │
│   ┌────┴────────┐                  ┌─────────────────────┐  │
│   │  Renderer   │ <───────────────  │  Schema Parser     │  │
│   │  (Flutter)  │    Screen        │  + Validator       │  │
│   └─────────────┘                  └─────────────────────┘  │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

## Quick Start

```dart
// 1. Create a session
final session = GenerativeUISession(
  config: providerConfig,
  modelId: 'gpt-4',
  userContext: GenerativeUIUserContext(
    deviceType: 'mobile',
    isDarkMode: true,
  ),
);

// 2. Start with an initial request
await for (final progress in session.start(
  instruction: 'Generate a dashboard with user stats',
  appContext: appContext,
)) {
  if (progress is _GenerativeUIComplete) {
    setState(() => _screen = progress.screen);
  }
}

// 3. Handle user interactions
void handleAction(Map<String, dynamic> action) async {
  final event = UIInteractionEvent.fromAction(action);
  
  await for (final progress in session.sendInteraction(
    event: event,
    appContext: appContext,
  )) {
    if (progress is _GenerativeUIComplete) {
      setState(() => _screen = progress.screen);
    }
  }
}

// 4. Render the UI
GenerativeScreen(
  spec: _screen,
  onAction: handleAction,
)
```

## Schema Definition

The schema is defined in `lib/generative_ui/schema.dart`.

### Core Types

#### Screen

```dart
class Screen {
  final String screenId;
  final ScreenRole? role;          // hero_screen | secondary_screen
  final Tone? tone;                // expressive | standard
  final MotionScheme? motionScheme;// expressive | standard | reduced
  final ColorMode? colorMode;      // brand | dynamic
  final List<Block> blocks;
}
```

#### Block Types

The `Block` type is a sealed class with the following variants:

**Layout & Content:**
- **HeroBlock**: Large header section with headline, subhead, and optional icon
- **CardBlock**: Container with headline, body content, and action buttons
- **TextBlock**: Simple text content with typography variants
- **ListBlock**: Vertical list of items
- **RowBlock**: Horizontal layout container
- **ColumnBlock**: Vertical layout container
- **SpacerBlock**: Empty space
- **DividerBlock**: Visual separator
- **ImageBlock**: Display images
- **AvatarBlock**: User avatars

**Interactive Controls:**
- **ButtonBlock**: Clickable buttons with roles (primary, secondary, destructive)
- **CheckboxBlock**: Toggle checkboxes
- **SwitchBlock**: On/off toggles
- **ChipBlock**: Selectable chips (filter, input, suggestion, assist)
- **IconButtonBlock**: Clickable icons
- **FabBlock**: Floating action buttons
- **TextFieldBlock**: Text input fields
- **SliderBlock**: Range sliders

**Feedback:**
- **ProgressBlock**: Linear or circular progress indicators
- **BadgeBlock**: Notification badges

### User Interaction Events

When users interact with UI components, events are sent back to the LLM:

| Event Type | Data | Trigger |
|------------|------|---------|
| `button_pressed` | `action` object | Button click |
| `checkbox_change` | `checked: bool` | Checkbox toggle |
| `switch_change` | `selected: bool` | Switch toggle |
| `chip_select` | `selected: bool, label: string` | Chip selection |
| `chip_pressed` | `label: string` | Chip click |
| `text_field_submit` | `value: string, fieldId: string` | Text field submit |
| `text_field_change` | `value: string, fieldId: string` | Text field change |
| `slider_change` | `value: number, fieldId: string` | Slider change |
| `icon_button_pressed` | `icon: string` | Icon button click |
| `fab_pressed` | action data | FAB click |
| `navigate` | `screen: string` | Navigation request |

#### Common Expressive Metadata

All blocks support these expressive properties:

```dart
Emphasis? emphasis;  // hero | primary | secondary | tertiary
Surface? surface;    // surface | surfaceVariant | primary | secondary | tertiary
Motion? motion;      // expressive | standard | reduced
```

## Renderer Mapping

The renderer (`lib/generative_ui/renderer.dart`) maps expressive metadata to Material 3 tokens:

### Emphasis → Visual Properties

| Emphasis  | Shape Radius | Elevation | Typography   | Padding |
|-----------|--------------|-----------|--------------|---------|
| hero      | 28           | 0         | displayMedium| 24      |
| primary   | 20           | 2         | headlineSmall| 20      |
| secondary | 16           | 1         | titleMedium  | 16      |
| tertiary  | 12           | 0         | bodyLarge    | 12      |

### Surface → Color Roles

| Surface        | Background Color         | On-Surface Color       |
|----------------|--------------------------|------------------------|
| surface        | colorScheme.surface      | colorScheme.onSurface  |
| surfaceVariant | colorScheme.surfaceVariant| colorScheme.onSurfaceVariant|
| primary        | colorScheme.primaryContainer| colorScheme.onPrimaryContainer|
| secondary      | colorScheme.secondaryContainer| colorScheme.onSecondaryContainer|
| tertiary       | colorScheme.tertiaryContainer| colorScheme.onTertiaryContainer|

### Motion → Animation Properties

| Motion     | Duration  | Easing              |
|------------|-----------|---------------------|
| expressive | 400ms     | Curves.easeOutBack  |
| standard   | 250ms     | Curves.easeInOut    |
| reduced    | 100ms     | Curves.linear       |

### Button Roles

| Role             | Button Style       | Position          |
|------------------|--------------------|--------------------|
| primary_action   | FilledButton       | Edge-hugging      |
| secondary_action | OutlinedButton     | Inline            |
| destructive      | FilledButton (error)| Inline           |

### Button Layouts

| Layout       | Behavior                                      |
|--------------|-----------------------------------------------|
| edge_hugging | Bottom-aligned, full-width on mobile          |
| inline       | Normal flow, auto-width                       |
| toolbar      | Arranged horizontally in app bar area         |

## LLM Integration

The LLM service (`lib/generative_ui/llm_service.dart`) handles conversational communication with the LLM.

### GenerativeUISession

The session maintains conversation history and handles the back-and-forth with the LLM:

```dart
// Create a session
final session = GenerativeUISession(
  config: providerConfig,
  modelId: modelId,
  userContext: userContext,
);

// Start with initial request
await for (final progress in session.start(
  instruction: 'Create a settings form',
  appContext: appContext,
)) {
  // Handle progress...
}

// Send user interaction
await for (final progress in session.sendInteraction(
  event: UIInteractionEvent.fromAction(action),
  appContext: appContext,
)) {
  // Handle progress...
}

// Send text message
await for (final progress in session.sendMessage(
  text: 'Add a dark mode toggle',
  appContext: appContext,
)) {
  // Handle progress...
}

// Clear and reset
session.clearHistory();
```

### System Prompt Guidelines

The system prompt instructs the LLM:

1. Output **only JSON** according to the `Screen` and `Block` types
2. React to user interactions by updating the UI appropriately
3. Use a small number of high-emphasis components:
   - At most 1 `hero` block per screen with `emphasis: "hero"`
   - Exactly 1 primary action button per main screen with `role: "primary_action"`
4. Use emphasis levels appropriately:
   - `hero` for the main hero section
   - `primary` for key content cards
   - `secondary` or `tertiary` for supporting content
5. Use `layout: "edge_hugging"` for main primary action on mobile screens
6. Respect `motionScheme` and reduced motion settings

### Validation

All LLM output is validated before rendering:
- JSON parsing with error handling
- Type validation for all fields
- Clamping/rejection of invalid values
- Unknown block types are filtered out

## API

### GenerativeScreen Widget

```dart
GenerativeScreen(
  spec: Screen,           // The screen specification
  onAction: (action) {},  // Callback when user interacts
  isLoading: false,       // Show loading state
  error: null,            // Show error state
  reduceMotion: false,    // Disable animations
)
```

### UIInteractionEvent

```dart
// Create from action map
final event = UIInteractionEvent.fromAction({
  'type': 'checkbox_change',
  'checked': true,
  'id': 'notifications',
});

// Or construct directly
final event = UIInteractionEvent(
  type: 'slider_change',
  data: {'value': 0.75, 'fieldId': 'volume'},
);
```

## Extending the Schema

To add a new block type:

1. Add the new variant to the `Block` sealed class in `schema.dart`
2. Add serialization/deserialization in `_parseBlock()`
3. Add a widget class for rendering in `renderer.dart`
4. Add the case to `_BlockRenderer.build()`
5. Update the system prompt to include the new block type
6. Document the new block type in this file

## Demo Feature

The demo screen is available at `lib/features/generative_ui/pages/generative_ui_demo_page.dart`.

### How to Test

1. Navigate to Settings → Generative UI Demo
2. The screen will start a conversational session with the LLM
3. The LLM generates an initial dashboard with real app data
4. Interact with UI elements (buttons, toggles, sliders, text fields)
5. Your interactions are sent back to the LLM
6. The LLM responds with updated UI
7. Use the text input at the bottom to send custom requests

### Feature Flag

The feature can be enabled/disabled via `SettingsProvider.generativeUIEnabled`.

## Security Considerations

- No runtime `eval()` of LLM output
- All JSON is parsed and validated against the strict schema
- Unknown fields are ignored, unknown block types are filtered
- API keys are never exposed to the LLM output

## Files Added/Changed

| File | Purpose |
|------|---------|
| `lib/generative_ui/schema.dart` | Schema type definitions |
| `lib/generative_ui/renderer.dart` | M3 Expressive renderer |
| `lib/generative_ui/llm_service.dart` | LLM integration |
| `lib/generative_ui/inline_generative_ui.dart` | Inline chat integration |
| `lib/features/generative_ui/pages/generative_ui_demo_page.dart` | Demo screen |
| `lib/features/chat/widgets/chat_message_widget.dart` | Updated with generative UI support |
| `docs/generative-ui-notes.md` | This documentation |
